{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max, min: [4.71142875 3.22041954 1.96897121] [-3.35557116 -4.00158058 -1.04102878]\n",
      "before voxelized: 12234\n",
      "max, min: [8.07 7.23 3.01] [0.01 0.01 0.01]\n",
      "after voxelized: 7677\n"
     ]
    }
   ],
   "source": [
    "pcd_path = \"data/kinth/pointcloud/1720509720.141261339.pcd\"\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "# pcd = pcd.voxel_down_sample(voxel_size=0.01)\n",
    "pcd = pcd.remove_radius_outlier(nb_points=25, radius=0.2)[0] # (pcd, new indexed from old)\n",
    "\n",
    "points = np.asarray(pcd.points)\n",
    "points = points - points.mean(axis=0)\n",
    "print(\"max, min:\", points.max(axis=0), points.min(axis=0))\n",
    "print(f\"before voxelized: {len(points)}\")\n",
    "points, _, _, _ = utils.voxel_downsample(points, 0.02, use_avg=False)\n",
    "print(\"max, min:\", points.max(axis=0), points.min(axis=0))\n",
    "print(f\"after voxelized: {len(points)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# height filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot = utils.get_average_pivot(points[:, 2])\n",
    "# points = points[points[:, 2] < pivot * 1.75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covariance rad feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eigval progress: 100%|████████████████████████████████████████| 1917/1917 [00:00<00:00, 4611.37it/s]\n",
      "eigval progress: 100%|████████████████████████████████████████| 1920/1920 [00:00<00:00, 4170.41it/s]\n",
      "eigval progress: 100%|████████████████████████████████████████| 1920/1920 [00:00<00:00, 3208.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing:0\n",
      "missing:0\n",
      "missing:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eigval progress: 100%|████████████████████████████████████████| 1920/1920 [00:00<00:00, 2984.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing:0\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import pickle\n",
    "\n",
    "search_radius = 2.5\n",
    "feat_rad_list = None\n",
    "feat_rad_list_dump_file = f\"data/kinth/pickle/feat_rad_{search_radius:.2f}_{osp.basename(pcd_path).split('.')[0]}.pkl\"\n",
    "\n",
    "# if osp.exists(feat_rad_list_dump_file):\n",
    "#     with open(feat_rad_list_dump_file, \"rb\") as f:\n",
    "#         feat_rad_list = pickle.load(f)\n",
    "# else:\n",
    "    # 多进程处理子空间坐标几何特征计算\n",
    "num_worker = 4\n",
    "batch_size = (len(points) - 1) // num_worker + 1 # round up\n",
    "feat_rad_list_con = [None] * num_worker\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=num_worker) as executor:\n",
    "    future_dict = {\n",
    "        executor.submit(\n",
    "            utils.eigval_radius,\n",
    "            points.copy(),\n",
    "            (i * batch_size, min((i + 1) * batch_size, len(points))),\n",
    "            search_radius\n",
    "        ) : i for i in range(num_worker)\n",
    "    }\n",
    "    for future in as_completed(future_dict):\n",
    "        feat_list, neighbor_num_record = future.result()\n",
    "        feat_rad_list_con[future_dict[future]] = feat_list\n",
    "        print(f\"missing:{(np.array(neighbor_num_record) < 3).astype(np.int32).sum()}\")\n",
    "feat_rad_list = np.concatenate(feat_rad_list_con, axis=0)\n",
    "    \n",
    "    # if not osp.exists(osp.dirname(feat_rad_list_dump_file)):\n",
    "    #     os.makedirs(osp.dirname(feat_rad_list_dump_file), exist_ok=True)\n",
    "    # with open(feat_rad_list_dump_file, \"wb\") as f:\n",
    "    #     pickle.dump(feat_rad_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.56037027 0.61389065 0.83025485]\n",
      " [0.40818853 0.69014165 0.81662227]\n",
      " [0.67753729 0.59564836 0.86961167]\n",
      " ...\n",
      " [0.40037955 0.95581884 0.97350807]\n",
      " [0.40037955 0.95581884 0.97350807]\n",
      " [0.40037955 0.95581884 0.97350807]]\n",
      "[[ 71  78 105]\n",
      " [ 54  91 108]\n",
      " [ 80  70 103]\n",
      " ...\n",
      " [ 43 104 106]\n",
      " [ 43 104 106]\n",
      " [ 43 104 106]]\n"
     ]
    }
   ],
   "source": [
    "print(feat_rad_list)\n",
    "feat_rad_color = feat_rad_list\n",
    "feat_rad_color = feat_rad_color / (feat_rad_color.sum(axis=1).reshape(-1, 1) + 1e-9)\n",
    "feat_rad_color = (feat_rad_color * 255.0).astype(np.int32)\n",
    "print(feat_rad_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.npy2ply(points, feat_rad_color, \"data/output/sample_rad.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty slot for staged run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covariance vtl feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eigval progress: 100%|████████████████████████████████████████| 1917/1917 [00:00<00:00, 4828.97it/s]\n",
      "eigval progress: 100%|████████████████████████████████████████| 1920/1920 [00:00<00:00, 4295.27it/s]\n",
      "eigval progress: 100%|████████████████████████████████████████| 1920/1920 [00:00<00:00, 3788.71it/s]\n",
      "eigval progress: 100%|████████████████████████████████████████| 1920/1920 [00:00<00:00, 3673.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing: 0\n",
      "missing: 0\n",
      "missing: 0\n",
      "missing: 0\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import pickle\n",
    "\n",
    "search_radius = 2.0\n",
    "feat_vtl_list = None\n",
    "feat_vtl_list_dump_file = f\"data/kinth/pickle/feat_vtl_{search_radius:.2f}_{osp.basename(pcd_path).split('.')[0]}.pkl\"\n",
    "\n",
    "# if osp.exists(feat_vtl_list_dump_file):\n",
    "#     with open(feat_vtl_list_dump_file, \"rb\") as f:\n",
    "#         feat_vtl_list = pickle.load(f)\n",
    "# else:\n",
    "    # 多进程处理子空间坐标几何特征计算\n",
    "num_worker = 4\n",
    "batch_size = (len(points) - 1) // num_worker + 1 # round up\n",
    "feat_vtl_list_con = [None] * num_worker\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=num_worker) as executor:\n",
    "    future_dict = {\n",
    "        executor.submit(\n",
    "            utils.eigval_vertic,\n",
    "            points,\n",
    "            (i * batch_size, min((i + 1) * batch_size, len(points))),\n",
    "            search_radius\n",
    "        ) : i for i in range(num_worker)\n",
    "    }\n",
    "    for future in as_completed(future_dict):\n",
    "        feat_list, neighbor_num_record = future.result()\n",
    "        print(f\"missing: {(np.array(neighbor_num_record) < 3).astype(np.int32).sum()}\")\n",
    "        feat_vtl_list_con[future_dict[future]] = feat_list\n",
    "feat_vtl_list = np.concatenate(feat_vtl_list_con, axis=0)\n",
    "    \n",
    "    # if not osp.exists(osp.dirname(feat_vtl_list_dump_file)):\n",
    "    #     os.makedirs(osp.dirname(feat_vtl_list_dump_file), exist_ok=True)\n",
    "    # with open(feat_vtl_list_dump_file, \"wb\") as f:\n",
    "    #     pickle.dump(feat_vtl_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80787677 0.0622222  0.58605761]\n",
      " [0.80787677 0.0622222  0.58605761]\n",
      " [0.80727165 0.06878825 0.58615755]\n",
      " ...\n",
      " [0.75716611 0.38267659 0.52939409]\n",
      " [0.75941932 0.36428799 0.53905154]\n",
      " [0.76012291 0.38032145 0.52684795]]\n",
      "[[141  10 102]\n",
      " [141  10 102]\n",
      " [140  11 102]\n",
      " ...\n",
      " [115  58  80]\n",
      " [116  55  82]\n",
      " [116  58  80]]\n"
     ]
    }
   ],
   "source": [
    "print(feat_vtl_list)\n",
    "feat_vtl_color = feat_vtl_list\n",
    "feat_vtl_color = feat_vtl_color / (feat_vtl_color.sum(axis=1).reshape(-1, 1) + 1e-9)\n",
    "feat_vtl_color = (feat_vtl_color * 255.0).astype(np.int32)\n",
    "print(feat_vtl_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.npy2ply(points, feat_vtl_color, \"data/output/sample_vtl.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster average feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eigval progress:   0%|                                                     | 0/7677 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m feat_avg_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      6\u001b[0m feat_avg_list_dump_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/kinth/pickle/feat_avg_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_radius\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mosp\u001b[38;5;241m.\u001b[39mbasename(pcd_path)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m feat_avg_list, neighbor_num_record \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavgvec_vertic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_radius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m feat_avg_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(feat_avg_list)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m((np\u001b[38;5;241m.\u001b[39marray(neighbor_num_record) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[0;32m~/fuguiduo/workspace/tmp/lasvisual/utils/tools.py:251\u001b[0m, in \u001b[0;36mavgvec_vertic\u001b[0;34m(points, be_range, border)\u001b[0m\n\u001b[1;32m    248\u001b[0m     neighbour_num_record\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(square_neighbours))\n\u001b[1;32m    250\u001b[0m     vec_cluster \u001b[38;5;241m=\u001b[39m square_neighbours \u001b[38;5;241m-\u001b[39m query\n\u001b[0;32m--> 251\u001b[0m     feat_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[43mcos_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec_cluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean())\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    253\u001b[0m feat_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(feat_list)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feat_list, neighbour_num_record\n",
      "File \u001b[0;32m~/fuguiduo/workspace/tmp/lasvisual/utils/tools.py:64\u001b[0m, in \u001b[0;36mcos_batch\u001b[0;34m(bat1, bat2)\u001b[0m\n\u001b[1;32m     62\u001b[0m res_dot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(bat1, bat2\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m     63\u001b[0m res_nml \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(bat1, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(bat2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m res_nml \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_dot \u001b[38;5;241m/\u001b[39m res_nml\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import pickle\n",
    "\n",
    "search_radius = 0.75\n",
    "feat_avg_list = None\n",
    "feat_avg_list_dump_file = f\"data/kinth/pickle/feat_avg_{search_radius:.2f}_{osp.basename(pcd_path).split('.')[0]}.pkl\"\n",
    "\n",
    "feat_avg_list, neighbor_num_record = utils.avgvec_vertic(points, (0, len(points)), search_radius)\n",
    "feat_avg_list = np.array(feat_avg_list)\n",
    "print((np.array(neighbor_num_record) <= 1).astype(np.int32).sum())\n",
    "# num_worker = 4\n",
    "# batch_size = (len(points) - 1) // num_worker + 1 # round up\n",
    "# feat_avg_list_con = [None] * num_worker\n",
    "\n",
    "# with ProcessPoolExecutor(max_workers=num_worker) as executor:\n",
    "#     future_dict = {\n",
    "#         executor.submit(\n",
    "#             utils.avgvec_vertic,\n",
    "#             points,\n",
    "#             (i * batch_size, min((i + 1) * batch_size, len(points))),\n",
    "#             search_radius\n",
    "#         ) : i for i in range(num_worker)\n",
    "#     }\n",
    "#     for future in as_completed(future_dict):\n",
    "#         feat_list, neighbor_num_record = future.result()\n",
    "#         print(f\"missing: {(np.array(neighbor_num_record) < 3).astype(np.int32).sum()}\")\n",
    "#         feat_avg_list_con[future_dict[future]] = feat_list\n",
    "# feat_avg_list = np.concatenate(feat_avg_list_con, axis=0)\n",
    "\n",
    "print(feat_avg_list)\n",
    "feat_avg_color = np.ones((len(points), 3))\n",
    "feat_avg_color = (feat_avg_color * feat_avg_list * 255.0).astype(np.int32)\n",
    "print(feat_avg_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.npy2ply(points, feat_avg_color, \"data/output/sample_avg.ply\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fgd-pcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
