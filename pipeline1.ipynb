{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# global import\n",
    "import os\n",
    "import numpy as np\n",
    "import utils\n",
    "import pickle\n",
    "\n",
    "# global variable\n",
    "voxel_size = 0.1 # which means 0.1 meter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of points after downsampled: (3352104, 3)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"./data/checkpoint/voxels.pkl\") and os.path.exists(\"./data/checkpoint/colors.pkl\"):\n",
    "    with open(\"./data/checkpoint/voxels.pkl\", \"rb\") as f:\n",
    "        voxels = pickle.load(f)\n",
    "    with open(\"./data/checkpoint/colors.pkl\", \"rb\") as f:\n",
    "        colors = pickle.load(f)\n",
    "else:\n",
    "    raw_points, raw_colors = utils.las2npy(\"../../dataset/001-010.las\") # shape (169438332, 3)\n",
    "    # rarefaction 体素滤波\n",
    "    raw_points = raw_points[::50]\n",
    "    raw_colors = raw_colors[::50]\n",
    "    voxels, idx_o2n, idx_n2o, unique_counts = utils.voxel_downsample(raw_points, voxel_size, True)\n",
    "    colors = raw_colors[idx_o2n]\n",
    "    with open(\"./data/checkpoint/voxels.pkl\", \"wb\") as f:\n",
    "        pickle.dump(voxels, f)\n",
    "    with open(\"./data/checkpoint/colors.pkl\", \"wb\") as f:\n",
    "        pickle.dump(colors, f)\n",
    "\n",
    "utils.npy2ply(voxels, colors, \"./data/pipeline_original.ply\")\n",
    "print(f\"number of points after downsampled: {voxels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height filtration section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行基于高程信息的基础滤波，这种滤波方法不能直接对整个点云集合处理，\n",
    "# 因为输电线路的架设不一定维持在同一海平面，均值滤波需要分成小批次处理\n",
    "start_point = 0\n",
    "march_steop = int(2.5e3)\n",
    "pivot_list = [] # pivot list\n",
    "stapt_list = [] # start point list\n",
    "\n",
    "boundary = voxels.shape[0]\n",
    "while start_point < boundary:\n",
    "    pivot = utils.get_average_pivot(voxels[start_point:min(start_point + march_steop, boundary), 2])\n",
    "    pivot_list.append(pivot)\n",
    "    stapt_list.append(start_point)\n",
    "    start_point += march_steop\n",
    "\n",
    "height_filter_mask = np.zeros((0, ), dtype=bool)\n",
    "for stapt, pivot in zip(stapt_list, pivot_list):\n",
    "    height_filter_mask = np.concatenate((height_filter_mask, voxels[stapt:min(stapt + march_steop, boundary), 2] > pivot))\n",
    "\n",
    "voxels_filteredby_height = voxels[height_filter_mask]\n",
    "colors_filteredby_height = colors[height_filter_mask]\n",
    "\n",
    "utils.npy2ply(voxels_filteredby_height, colors_filteredby_height, \"./data/pipeline_height_filtration.ply\", use_txt=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power line extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多进程处理子空间坐标几何特征计算\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "if os.path.exists(\"./data/checkpoint/line_feat_mat.pkl\"):\n",
    "    with open(\"./data/checkpoint/line_feat_mat.pkl\", \"rb\") as f:\n",
    "        line_feat_mat = pickle.load(f)\n",
    "else:\n",
    "    num_workers = 4\n",
    "    batch_size = voxels_filteredby_height.shape[0] // num_workers\n",
    "    line_feat_mat_list = [None] * num_workers\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures_dict = {\n",
    "            executor.submit(\n",
    "                utils.eigval_radius,\n",
    "                voxels_filteredby_height[i * batch_size : (i + 1) * batch_size],\n",
    "                voxel_size * 75.0\n",
    "            ) : i for i in range(num_workers)\n",
    "        }\n",
    "        for future in as_completed(futures_dict):\n",
    "            feat_mat, _ = future.result()\n",
    "            line_feat_mat_list[futures_dict[future]] = feat_mat\n",
    "    line_feat_mat = np.concatenate(line_feat_mat_list, axis=0)\n",
    "    with open(\"./data/checkpoint/line_feat_mat.pkl\", \"wb\") as f:\n",
    "        pickle.dump(line_feat_mat, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51.03776573 51.10588386 14.84088054]\n",
      "[0. 0. 0.]\n",
      "[[  0   0   0]\n",
      " [  7   9  23]\n",
      " [  9  27  51]\n",
      " ...\n",
      " [ 15  51  55]\n",
      " [  9  55  98]\n",
      " [  8  65 133]]\n"
     ]
    }
   ],
   "source": [
    "# 因为使用了多进程分组处理，所以有可能原先分组不能整除刚好分给各个进程\n",
    "# 因此处理后的掩码长度也许和原点云坐标数量不一，需要按照掩码的长度调整\n",
    "voxels_filteredby_height = voxels_filteredby_height[:line_feat_mat.shape[0]]\n",
    "colors_filteredby_height = colors_filteredby_height[:line_feat_mat.shape[0]]\n",
    "\n",
    "line_feat_max = np.max(line_feat_mat, axis=0)\n",
    "line_feat_min = np.min(line_feat_mat, axis=0)\n",
    "print(line_feat_max)\n",
    "print(line_feat_min)\n",
    "line_feat_rgb = ((line_feat_mat - line_feat_min) / line_feat_max * 255.0).astype(np.int32)\n",
    "print(line_feat_rgb)\n",
    "utils.npy2ply(voxels_filteredby_height, line_feat_rgb, \"./data/pipeline_height_filtration_vis.ply\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_mask = (line_feat_mat[:, 0] > line_feat_mat[:, 0].mean()) & (line_feat_mat[:, 1] > line_feat_mat[:, 1].mean())\n",
    "# 获取电力线点云\n",
    "voxels_line = voxels_filteredby_height[line_mask]\n",
    "colors_line = colors_filteredby_height[line_mask]\n",
    "\n",
    "def radius_filtration(data: np.ndarray, radius: float):\n",
    "    import open3d as o3d\n",
    "    from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "    o3d_pcd = utils.npy2o3d(data)\n",
    "    search_tree = o3d.geometry.KDTreeFlann(o3d_pcd)\n",
    "\n",
    "    def radius_search(idx):\n",
    "        k, idx, _ = search_tree.search_radius_vector_3d(data[idx], radius)\n",
    "        return k\n",
    "\n",
    "    num_neigbgours = np.array([0] * len(data))\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures_dict = {executor.submit(radius_search, i) : i for i in range(len(data))}\n",
    "        for future in as_completed(futures_dict):\n",
    "            num_neigbgours[futures_dict[future]] = future.result()\n",
    "    \n",
    "    return num_neigbgours > num_neigbgours.mean() / 4.0\n",
    "\n",
    "# line_noise_filter_mask = radius_filtration(voxels_line, voxel_size * 30.0)\n",
    "# voxels_line = voxels_line[line_noise_filter_mask]\n",
    "# colors_line = colors_line[line_noise_filter_mask]\n",
    "\n",
    "utils.npy2ply(voxels_line, colors_line, \"./data/pipeline_line.ply\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tower extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_excluded_mask = ~line_mask & (line_feat_mat[:, 0] < line_feat_mat[:, 0].mean()) & (line_feat_mat[:, 1] < line_feat_mat[:, 1].mean())\n",
    "voxels_line_excluded = voxels_filteredby_height[line_excluded_mask]\n",
    "colors_line_excluded = colors_filteredby_height[line_excluded_mask]\n",
    "utils.npy2ply(voxels_line_excluded, colors_line_excluded, \"./data/pipeline_line_excluded.ply\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"./data/checkpoint/tower_feat_mat.pkl\"):\n",
    "    with open(\"./data/checkpoint/tower_feat_mat.pkl\", \"rb\") as f:\n",
    "        tower_feat_mat = pickle.load(f)\n",
    "else:\n",
    "    num_workers = 4\n",
    "    batch_size = voxels_line_excluded.shape[0] // num_workers\n",
    "    tower_feat_mat_list = [None] * num_workers\n",
    "    from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures_dict = {\n",
    "            executor.submit(\n",
    "                utils.eigval_vertic,\n",
    "                voxels_line_excluded[i * batch_size:(i + 1) * batch_size],\n",
    "                voxel_size * 75.0\n",
    "            ) : i for i in range(num_workers)\n",
    "        }\n",
    "\n",
    "        for future in as_completed(futures_dict):\n",
    "            feat_mat, _ = future.result()\n",
    "            tower_feat_mat_list[futures_dict[future]] = feat_mat\n",
    "    tower_feat_mat = np.concatenate(tower_feat_mat_list, axis=0)\n",
    "    with open(\"./data/checkpoint/tower_feat_mat.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tower_feat_mat, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79207\n"
     ]
    }
   ],
   "source": [
    "# 也许这里会损失一些额外的点云，由于前面的处理方法的遗留问题\n",
    "voxels_line_excluded = voxels_line_excluded[:len(tower_feat_mat)]\n",
    "colors_line_excluded = colors_line_excluded[:len(tower_feat_mat)]\n",
    "\n",
    "tower_feat_max = np.max(tower_feat_mat, axis=0)\n",
    "tower_feat_min = np.min(tower_feat_mat, axis=0)\n",
    "tower_feat_rgb = ((tower_feat_mat - tower_feat_min) / tower_feat_max * 255.0).astype(np.int32)\n",
    "utils.npy2ply(voxels_line_excluded, tower_feat_rgb, \"./data/pipeline_line_excluded_vis.ply\")\n",
    "\n",
    "tower_feat_mat = (tower_feat_mat - tower_feat_min) / tower_feat_max # normalized to [0, 1]\n",
    "half_max_height = np.median(tower_feat_mat[:, 1])\n",
    "tower_mask = \\\n",
    "    (tower_feat_mat[:, 0] > 0.25) & \\\n",
    "    (tower_feat_mat[:, 1] > half_max_height) & \\\n",
    "    (tower_feat_mat[:, 2] < 0.1)\n",
    "print(tower_mask.astype(np.int32).sum())\n",
    "voxels_tower = voxels_line_excluded[tower_mask]\n",
    "colors_tower = colors_line_excluded[tower_mask]\n",
    "utils.npy2ply(voxels_tower, colors_tower, \"./data/pipeline_tower.ply\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of clustered towers: 11\n",
      "tower point threshold: 3588.0\n",
      "valid labels: [ 0  1  2  3  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "# denoised 降噪\n",
    "labels = np.array(utils.npy2o3d(voxels_tower).cluster_dbscan(eps=voxel_size * 75.0, min_points=100, print_progress=False))\n",
    "if labels.shape[0] != voxels_tower.shape[0]:\n",
    "    raise ValueError(\"mismatched label num\")\n",
    "\n",
    "print(f\"number of clustered towers: {labels.max() + 1}\")\n",
    "unique_labels, labels_count = np.unique(labels, return_counts=True)\n",
    "\n",
    "unique_labels = unique_labels[1:]\n",
    "labels_count = labels_count[1:]\n",
    "min_threshold = labels_count.mean() // 2\n",
    "label_selection = labels_count > min_threshold\n",
    "valid_labels = unique_labels[label_selection]\n",
    "print(f\"tower point threshold: {min_threshold}\")\n",
    "\n",
    "print(f\"valid labels: {valid_labels}\")\n",
    "tower_denoised_mask = [(labels == label_idx) for label_idx in valid_labels]\n",
    "tower_denoised_mask = np.logical_or.reduce(\n",
    "    np.vstack(tower_denoised_mask),\n",
    "    axis=0\n",
    ")\n",
    "voxels_tower_denoised = voxels_tower[tower_denoised_mask]\n",
    "colors_tower_denoised = colors_tower[tower_denoised_mask]\n",
    "\n",
    "utils.npy2ply(\n",
    "        voxels_tower_denoised,\n",
    "        colors_tower_denoised,\n",
    "    \"./data/pipeline_tower_denoised.ply\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cluster: 10\n",
      "tower#1: 07304\n",
      "tower#2: 15903\n",
      "tower#3: 05230\n",
      "tower#4: 08318\n",
      "tower#5: 08530\n",
      "tower#6: 05297\n",
      "tower#7: 08097\n",
      "tower#8: 07507\n",
      "tower#9: 07592\n",
      "tower#10: 03610\n"
     ]
    }
   ],
   "source": [
    "tower_instanced_labels = utils.cluster_instanced(voxels_tower_denoised, voxel_size * 200.0, min_threshold)\n",
    "# 自己写的这个基于垂直方向的聚类函数，标签是从1开始的，因此不需要在最大标签值+1，因为这里的标签下标不是从0开始的\n",
    "print(f\"number of cluster: {tower_instanced_labels.max()}\")\n",
    "voxels_tower_instanced = voxels_tower_denoised\n",
    "colors_tower_instanced = np.vstack([np.array([0, 0, 0])] * len(voxels_tower_instanced))\n",
    "for label in range(1, tower_instanced_labels.max() + 1):\n",
    "    print(f\"tower#{label}: {(tower_instanced_labels == label).astype(np.int32).sum():05d}\")\n",
    "    colors_tower_instanced[tower_instanced_labels == label] = np.array([\n",
    "        np.random.randint(100, 255),\n",
    "        np.random.randint(100, 255),\n",
    "        np.random.randint(100, 255)\n",
    "    ])\n",
    "utils.npy2ply(voxels_tower_instanced, colors_tower_instanced, \"./data/pipeline_tower_instanced.ply\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation using line's and tower's position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of voxels in line:\t86354\n",
      "number of voxels in tower:\t79207\n",
      "number of label in line:\t138810\n",
      "number of label in tower:\t241311\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of voxels in line:\\t{len(voxels_line)}\")\n",
    "print(f\"number of voxels in tower:\\t{len(voxels_tower)}\")\n",
    "\n",
    "def position_instanced_radius(points: np.ndarray, poses: np.ndarray, radius: float):\n",
    "    import open3d as o3d\n",
    "    \n",
    "    o3d_pcd = utils.npy2o3d(points)\n",
    "    search_tree = o3d.geometry.KDTreeFlann(o3d_pcd)\n",
    "\n",
    "    instanced_labels = np.zeros((len(points), ), dtype=bool)\n",
    "\n",
    "    for query in poses:\n",
    "        neighbour_num, neighbour_indicies, _ = search_tree.search_radius_vector_3d(query, radius)\n",
    "        instanced_labels[neighbour_indicies] = True\n",
    "    \n",
    "    return instanced_labels\n",
    "\n",
    "def position_instanced_vertical(points: np.ndarray, poses: np.ndarray, border: float):\n",
    "    instanced_labels = np.zeros((len(points), ), dtype=np.int32)\n",
    "\n",
    "    instanced_labels = np.zeros((len(points), ), dtype=bool)\n",
    "    for query in poses:\n",
    "        square_selection = (np.abs(points[:, 0] - query[0]) < border) & (np.abs(points[:, 1] - query[1]) < border)\n",
    "        instanced_labels = instanced_labels | square_selection\n",
    "    \n",
    "    return square_selection\n",
    "\n",
    "\n",
    "\n",
    "labels_line = position_instanced_radius(voxels, voxels_line, voxel_size * 20.0)\n",
    "labels_tower = np.array([False] * len(voxels))\n",
    "\n",
    "for tower_idx in range(1, tower_instanced_labels.max() + 1):\n",
    "    labels_tower = labels_tower | position_instanced_vertical(\n",
    "        voxels,\n",
    "        np.array([voxels_tower_denoised[tower_instanced_labels == tower_idx].mean(axis=0)]),\n",
    "        voxel_size * 125.0\n",
    "    )\n",
    "\n",
    "print(f\"number of label in line:\\t{labels_line.astype(np.int32).sum()}\")\n",
    "print(f\"number of label in tower:\\t{labels_tower.astype(np.int32).sum()}\")\n",
    "\n",
    "\n",
    "# give different colors to line and tower\n",
    "colors_labeled = colors\n",
    "colors_labeled[labels_line] = np.array([100, 255, 255])\n",
    "colors_labeled[labels_tower] = np.array([255, 100, 100])\n",
    "\n",
    "utils.npy2ply(voxels, colors_labeled, \"./data/pipeline_final.ply\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据电力线提取主要走向\n",
    "_, main_axis = utils.pca_k(voxels_line, 1)\n",
    "tower_indicies = [i for i in range(1, tower_instanced_labels.max() + 1)]\n",
    "tower_centers = [voxels_tower_denoised[tower_instanced_labels == tower_idx].mean(axis=0) for tower_idx in tower_indicies]\n",
    "\n",
    "# 求杆塔中心到走线主方向上的投影长度，并以此为排序依据\n",
    "# 1. 假设有向量u, v\n",
    "# 2. u 投影到 v 上得到 u'\n",
    "# 3. u' 的模长是d\n",
    "# 4. v / |v| 得到主方向的单位向量\n",
    "# 5. d * (v / |v|) 得到 u 投影到 v 上的实际最终向量\n",
    "# 6. d = |u| * cos(theta)\n",
    "# 7. cose(theta) = (u * v) / (|u| * |v|)\n",
    "# 8. u' = (u * v) / (|v|^2) * v \n",
    "tower_centers_on_main_axis = [\n",
    "    np.linalg.norm((np.dot(tower_center, main_axis) / np.linalg.norm(main_axis) ** 2) * main_axis) for tower_center in tower_centers\n",
    "]\n",
    "\n",
    "# 根据在主方向上投影的距离来排序杆塔\n",
    "tower_sequence = np.array(tower_centers_on_main_axis).argsort()[::-1]\n",
    "\n",
    "# 选取相邻的杆塔来截取电力线\n",
    "line_steps_mask = []\n",
    "for idx in range(len(tower_sequence) - 1):\n",
    "    tower_center1 = tower_centers[tower_sequence[idx]]\n",
    "    tower_center2 = tower_centers[tower_sequence[idx + 1]]\n",
    "\n",
    "    # 求得垂直于线段的两个平面，两个平面之间的电力线点云分为一档电力线\n",
    "    \n",
    "    normal_vec = tower_center1 - tower_center2\n",
    "    normal_vec[2] = 0.0\n",
    "    d1 = -np.dot(normal_vec, tower_center1)\n",
    "    d2 = -np.dot(normal_vec, tower_center2)\n",
    "\n",
    "    # 如果距离两个平面的距离之乘积是负数，说明该点位于两个平面之间\n",
    "    line_steps_mask.append(\n",
    "        (np.dot(voxels[labels_line], normal_vec) + d1) * \\\n",
    "        (np.dot(voxels[labels_line], normal_vec) + d2) < 0.0\n",
    "    )\n",
    "\n",
    "# for mask in line_steps_mask:\n",
    "#     print(f\"{mask.astype(np.int32).sum()} / {mask.shape[0]}\")\n",
    "\n",
    "colors_line_seperated = colors\n",
    "for mask in line_steps_mask:\n",
    "    colors_line_seperated[np.where(labels_line)[0][mask]]= np.array([\n",
    "        np.random.randint(50, 255),\n",
    "        np.random.randint(50, 255),\n",
    "        np.random.randint(50, 255)\n",
    "    ])\n",
    "\n",
    "utils.npy2ply(\n",
    "    voxels,\n",
    "    colors_line_seperated,\n",
    "    \"./data/pipeline_powerline_step.ply\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4416, 3)\n"
     ]
    }
   ],
   "source": [
    "# grab a sample to experiment\n",
    "\n",
    "# the variable `labels_line` is the mask of power line among the\n",
    "# original point cloud. Then `line_steps_mask` further  seperate\n",
    "# power line points into several segments between each tower.\n",
    "line_sample = voxels[np.where(labels_line)[0][line_steps_mask[8]]]\n",
    "\n",
    "eigvals, eigvecs = utils.pca_k(line_sample, 3)\n",
    "# transform to new basis given by PCA\n",
    "line_sample = line_sample @ eigvecs\n",
    "\n",
    "color_sample = np.array([[100, 100, 100]] * line_sample.shape[0])\n",
    "print(color_sample.shape)\n",
    "for i in range(3):\n",
    "    line_sample_view = np.copy(line_sample)\n",
    "    line_sample_view[:, i] = 0.0\n",
    "    utils.npy2ply(line_sample_view, color_sample, f\"./data/test_sample_axis{i}.ply\")\n",
    "\n",
    "# projected_to_axis1 = line_sample @ eigvecs[:, 0]\n",
    "# min_on_axis1 = np.min(projected_to_axis1)\n",
    "# max_on_axis1 = np.max(projected_to_axis1)\n",
    "# num_slices = 100 # hyperparameter\n",
    "# len_per_slice = (max_on_axis1 - min_on_axis1) / num_slices\n",
    "# projected_to_axis1 = projected_to_axis1 - min_on_axis1\n",
    "# transformed_cnt = []\n",
    "# for i in range(num_slices):\n",
    "#     mask = (projected_to_axis1 > (i * len_per_slice)) & (projected_to_axis1 < ((i + 1) * len_per_slice))\n",
    "#     line_segment = line_sample[mask][:, 1:] # noneed to count in the first axis\n",
    "#     if line_segment.shape[0] > 8:\n",
    "#         center_point = np.mean(line_segment, axis=0)\n",
    "#         transformed_cnt.append(line_segment - center_point)\n",
    "# transformed_cnt = np.vstack(transformed_cnt)\n",
    "\n",
    "\n",
    "# # do some visualization\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set_style(\"darkgrid\")\n",
    "\n",
    "# plot_data_x = transformed_cnt[:, 0]\n",
    "# plot_data_y = transformed_cnt[:, 1]\n",
    "# sns.scatterplot(x=plot_data_x, y=plot_data_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
